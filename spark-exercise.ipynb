{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7125c879",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6211004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark.range(5).show()\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7687961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2323f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/20 09:37:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f7b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd565d",
   "metadata": {},
   "source": [
    "# 1)Create a spark data frame that contains your favorite programming languages.\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffaa47",
   "metadata": {},
   "source": [
    "### The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9ca3236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    languages\n",
       "0         SQL\n",
       "1      Python\n",
       "2        HTML\n",
       "3  JavaScript"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pandas_dataframe = pd.DataFrame({'Python', 'SQL', 'HTML', 'JavaScript',}, columns = ['languages'])\n",
    "pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = spark.createDataFrame(pandas_dataframe)\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1600ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "language.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e822f6",
   "metadata": {},
   "source": [
    "# 2)Load the mpg dataset as a spark dataframe.\n",
    "- Create 1 column of output that contains a message like the one below:\n",
    ">The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e697ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|             model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|                a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|                a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|                a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|  auto(s6)|  4| 19| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|manual(m5)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|manual(m6)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a6 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 24|  p|midsize|\n",
      "|        audi|        a6 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|midsize|\n",
      "|        audi|        a6 quattro|  4.2|2008|  8|  auto(s6)|  4| 16| 23|  p|midsize|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 14| 20|  r|    suv|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 11| 15|  e|    suv|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ddc700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#renaming a columns weird\n",
    "# The 1999 audi a4 has a 4 cylinder engine\n",
    "mpg.filter(mpg.cyl == 4).filter(mpg.year == 1999).filter(mpg.model == 'a4').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cffa28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.createOrReplaceTempView(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9f18772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             summary|\n",
      "+--------------------+\n",
      "|The 1999 audi a4h...|\n",
      "|The 1999 audi a4h...|\n",
      "|The 2008 audi a4h...|\n",
      "|The 2008 audi a4h...|\n",
      "|The 1999 audi a4h...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT CONCAT(\"The \", year, \" \", manufacturer, \" \", model, \"has a \", cyl, \" cylinder engine.\") as summary\n",
    "FROM mpg\n",
    "'''\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef90691",
   "metadata": {},
   "source": [
    "# Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cedd6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-----------+\n",
      "|     trans|regexp_extract|regexp_replace|when + like|\n",
      "+----------+--------------+--------------+-----------+\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "+----------+--------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    'trans',\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\\(\", 1).alias(\"regexp_extract\"),\n",
    "    regexp_replace(\"trans\", r\"\\(.+$\", \"\").alias(\"regexp_replace\"),\n",
    "    when(\n",
    "        mpg.trans.like(\"auto%\"), \"auto\"\n",
    "    ).otherwise(\"manual\").alias(\"when + like\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302a85c",
   "metadata": {},
   "source": [
    "# 3)Load the tips dataset as a spark dataframe.\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e1575",
   "metadata": {},
   "source": [
    "### What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4492409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e0e531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|smoker|count|            percent|\n",
      "+------+-----+-------------------+\n",
      "|    No|  151| 0.6188524590163934|\n",
      "|   Yes|   93|0.38114754098360654|\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tips.groupby('smoker').count().withColumn('percent', col('count') / tips.count()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66b4d6",
   "metadata": {},
   "source": [
    "### Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "461b5028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.withColumn(\"tip_percentage\", expr('tip / total_bill')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42229b",
   "metadata": {},
   "source": [
    "### Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65231255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|   sex|    No|   Yes|\n",
      "+------+------+------+\n",
      "|Female|0.1569|0.1822|\n",
      "|  Male|0.1607|0.1528|\n",
      "+------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# method chaining - df.method1().method2()....\n",
    "(\n",
    "    tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill'))\n",
    "    .groupby(\"sex\")\n",
    "    .pivot(\"smoker\") # make a pivot table\n",
    "    .agg(round(mean(\"tip_percentage\"), 4))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4732bb4",
   "metadata": {},
   "source": [
    "# 4)Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6c40f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ebf99",
   "metadata": {},
   "source": [
    "### Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69e7401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = weather.withColumn(\n",
    "    \"temp_max\", (col(\"temp_max\") * 9 / 5 + 32)\n",
    ").withColumn(\"temp_min\", (col(\"temp_min\") * 9 / 5 + 32))\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e14a65",
   "metadata": {},
   "source": [
    "### Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "573aa5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = (\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(sum(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe96f1f",
   "metadata": {},
   "source": [
    "### Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dbfc6265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(year=2012, total_winds=1244.7),\n",
       " Row(year=2014, total_winds=1236.5000000000007),\n",
       " Row(year=2015, total_winds=1153.3000000000002),\n",
       " Row(year=2013, total_winds=1100.8000000000006)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_winds\"))\n",
    "    .sort(col(\"total_winds\").desc())\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73afcb0",
   "metadata": {},
   "source": [
    "### What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "931ffcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 83:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(col(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a753fc6",
   "metadata": {},
   "source": [
    "### What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cf4fb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|average_high_temp| average_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca690a4",
   "metadata": {},
   "source": [
    "### What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b35bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
